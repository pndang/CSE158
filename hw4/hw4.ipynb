{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from gensim.models import Word2Vec\n",
    "import dateutil\n",
    "from scipy.sparse import lil_matrix # To build sparse feature matrices, if you like\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "f = gzip.open(\"data/steam_category.json.gz\")\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)\n",
    "    if len(dataset) >= 20000:\n",
    "        break\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 10000\n",
    "Ntest = 10000\n",
    "\n",
    "dataTrain = dataset[:Ntrain]\n",
    "dataTest = dataset[Ntrain:Ntrain + Ntest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userID': 'u74382925',\n",
       " 'genre': 'Adventure',\n",
       " 'early_access': False,\n",
       " 'reviewID': 'r75487422',\n",
       " 'hours': 4.1,\n",
       " 'text': 'Short Review:\\nA good starting chapter for this series, despite the main character being annoying (for now) and a short length. The story is good and actually gets more interesting. Worth the try.\\nLong Review:\\nBlackwell Legacy is the first on the series of (supposedly) 5 games that talks about the main protagonist, Rosangela Blackwell, as being a so called Medium, and in this first chapter we get to know how her story will start and how she will meet her adventure companion Joey...and really, that\\'s really all for for now and that\\'s not a bad thing, because in a way this game wants to show how hard her new job is, and that she cannot escape her destiny as a medium.\\nMy biggest complain for this chapter, except the short length, it\\'s the main protagonist being a \"bit\" too annoying to be likeable, and most of her dialogues will always be about complaining or just be annoyed. Understandable, sure, but lighten\\' up will ya!?\\nHowever, considering that in the next installments she will be much more likeable and kind of interesting, I\\'d say give it a shot and see if you like it: if you hate this first game, you might like the next, or can always stop here.\\nI recommend it.',\n",
       " 'genreID': 3,\n",
       " 'date': '2014-02-07'}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTrainText = [datum['text'] for datum in dataTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \\ before certain punctuations as they represent special characters in regex\n",
    "\n",
    "specialChars = ['.', '*', '?', '+', '^', '$', '[', ']', '(', ')']\n",
    "spGrouped = '|'.join(sp)\n",
    "\n",
    "saw = []\n",
    "for _ in range(len(spGrouped)):\n",
    "    if (spGrouped[_] in specialChars) and (spGrouped[_] not in saw):\n",
    "        saw.append(spGrouped[_])\n",
    "        spGrouped = spGrouped[:_]+'\\\\'+spGrouped[_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = rf'{spGrouped}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTrainText = []\n",
    "\n",
    "for _ in range(len(allTrainText)):\n",
    "    newString = re.sub(pattern, '', allTrainText[_])\n",
    "    cleanTrainText.append(newString.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common words in train text corpus\n",
    "\n",
    "commonWords = defaultdict(int)\n",
    "\n",
    "for t in cleanTrainText:\n",
    "    words = t.split()\n",
    "    for w in words:\n",
    "        if w == 'i':\n",
    "            allIs.append(w)\n",
    "        commonWords[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(commonWords.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34211),\n",
       " ('and', 19392),\n",
       " ('a', 18791),\n",
       " ('to', 18077),\n",
       " ('game', 15043),\n",
       " ('of', 14095),\n",
       " ('is', 13000),\n",
       " ('you', 12735),\n",
       " ('i', 12201),\n",
       " ('it', 11824)]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = commonWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 34211),\n",
       " ('and', 19392),\n",
       " ('a', 18791),\n",
       " ('to', 18077),\n",
       " ('game', 15043),\n",
       " ('of', 14095),\n",
       " ('is', 13000),\n",
       " ('you', 12735),\n",
       " ('i', 12201),\n",
       " ('it', 11824)]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataTrain:\n",
    "  r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList([x[0] for x in answers['Q1']], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "NW = 1000 # dictionary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [_[1] for _ in countsClassCode[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X...\n",
    "\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "\n",
    "def feat_q2(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordID[w]] += 1\n",
    "    return feat\n",
    "\n",
    "X = [feat_q2(datum) for datum in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [datum['genreID'] for datum in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:Ntrain]\n",
    "ytrain = y[:Ntrain]\n",
    "Xtest = X[Ntrain:]\n",
    "ytest = y[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phuro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mod.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = preds == ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [(34211, 'the'),\n",
       "  (19392, 'and'),\n",
       "  (18791, 'a'),\n",
       "  (18077, 'to'),\n",
       "  (15043, 'game'),\n",
       "  (14095, 'of'),\n",
       "  (13000, 'is'),\n",
       "  (12735, 'you'),\n",
       "  (12204, 'i'),\n",
       "  (11824, 'it')],\n",
       " 'Q2': 0.6374}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetWords = ['character', 'game', 'length', 'a', 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFrequency = defaultdict(int)\n",
    "for datum in dataTrain:\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in set(r.split()):\n",
    "        docFrequency[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    r = ''.join([c for c in text.lower() if not c in punctuation])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency for words in the first text corpus in train set\n",
    "\n",
    "termFreq = defaultdict(int)\n",
    "t = clean(dataTrain[0]['text'])\n",
    "for w in t.split():\n",
    "    termFreq[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3Answer = []\n",
    "for w in targetWords:\n",
    "    idf = math.log10(len(dataTrain) / docFrequency[w])\n",
    "    tfidf = termFreq[w] * math.log10(len(dataTrain) / docFrequency[w])\n",
    "    q3Answer.append((idf, tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = q3Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList([x[0] for x in answers['Q3']], 5)\n",
    "assertFloatList([x[1] for x in answers['Q3']], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [(34211, 'the'),\n",
       "  (19392, 'and'),\n",
       "  (18791, 'a'),\n",
       "  (18077, 'to'),\n",
       "  (15043, 'game'),\n",
       "  (14095, 'of'),\n",
       "  (13000, 'is'),\n",
       "  (12735, 'you'),\n",
       "  (12204, 'i'),\n",
       "  (11824, 'it')],\n",
       " 'Q2': 0.6374,\n",
       " 'Q3': [(1.453457336521869, 1.453457336521869),\n",
       "  (0.22951619056889208, 0.45903238113778416),\n",
       "  (2.2441251443275085, 4.488250288655017),\n",
       "  (0.3047810810948491, 2.4382486487587927),\n",
       "  (0.376647318462008, 1.129941955386024)]}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "topWords = [_[1] for _ in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordID = dict(zip(topWords, range(len(topWords))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(int)\n",
    "\n",
    "for datum in dataTrain:\n",
    "    text = clean(datum['text'])\n",
    "    for w in set(text.split()):\n",
    "        if w in topWords:\n",
    "            df[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_q4(text):\n",
    "    feat = []\n",
    "    text = clean(text)\n",
    "    tf = defaultdict(int)\n",
    "\n",
    "    for w in text.split():\n",
    "        tf[w] += 1\n",
    "    for w in topWords:\n",
    "        tfidf = tf[w] * math.log10(len(dataTrain) / df[w])\n",
    "        feat.append(tfidf)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X and y...\n",
    "\n",
    "X = [feat_q4(datum['text']) for datum in dataset]\n",
    "y = [datum['genreID'] for datum in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:Ntrain]\n",
    "ytrain = y[:Ntrain]\n",
    "Xtest = X[Ntrain:]\n",
    "ytest = y[Ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phuro\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mod.predict(Xtest)\n",
    "correct = preds == ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [(34211, 'the'),\n",
       "  (19392, 'and'),\n",
       "  (18791, 'a'),\n",
       "  (18077, 'to'),\n",
       "  (15043, 'game'),\n",
       "  (14095, 'of'),\n",
       "  (13000, 'is'),\n",
       "  (12735, 'you'),\n",
       "  (12204, 'i'),\n",
       "  (11824, 'it')],\n",
       " 'Q2': 0.6374,\n",
       " 'Q3': [(1.453457336521869, 1.453457336521869),\n",
       "  (0.22951619056889208, 0.45903238113778416),\n",
       "  (2.2441251443275085, 4.488250288655017),\n",
       "  (0.3047810810948491, 2.4382486487587927),\n",
       "  (0.376647318462008, 1.129941955386024)],\n",
       " 'Q4': 0.6217}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(x1,x2):\n",
    "    numer, norm1, norm2 = 0, 0, 0\n",
    "    for a1,a2 in zip(x1,x2):\n",
    "        numer += a1*a2\n",
    "        norm1 += a1**2\n",
    "        norm2 += a2**2\n",
    "    if norm1*norm2:\n",
    "        return numer / math.sqrt(norm1*norm2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {}\n",
    "firstInTest = feat_q4(dataTrain[0]['text'])\n",
    "\n",
    "for datum in dataTest:\n",
    "    feat = feat_q4(datum['text'])\n",
    "    sim = Cosine(firstInTest, feat)\n",
    "    similarities[datum['reviewID']] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = sorted(similarities.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = (similarities[0][1], similarities[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q5'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [(34211, 'the'),\n",
       "  (19392, 'and'),\n",
       "  (18791, 'a'),\n",
       "  (18077, 'to'),\n",
       "  (15043, 'game'),\n",
       "  (14095, 'of'),\n",
       "  (13000, 'is'),\n",
       "  (12735, 'you'),\n",
       "  (12204, 'i'),\n",
       "  (11824, 'it')],\n",
       " 'Q2': 0.6374,\n",
       " 'Q3': [(1.453457336521869, 1.453457336521869),\n",
       "  (0.22951619056889208, 0.45903238113778416),\n",
       "  (2.2441251443275085, 4.488250288655017),\n",
       "  (0.3047810810948491, 2.4382486487587927),\n",
       "  (0.376647318462008, 1.129941955386024)],\n",
       " 'Q4': 0.6217,\n",
       " 'Q5': (0.48266773388727985, 'r65720011')}"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455\n",
      "Found better c: c = 0.1, acc = 0.6455\n",
      "0.6318\n",
      "0.6267\n",
      "0.6235\n",
      "0.6217\n"
     ]
    }
   ],
   "source": [
    "cValues = np.linspace(0.1, 1, 5)\n",
    "bestAcc = None\n",
    "\n",
    "for c in cValues:\n",
    "    mod = linear_model.LogisticRegression(C=c)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    preds = mod.predict(Xtest)\n",
    "    correct = preds == ytest\n",
    "    acc = sum(correct) / len(correct)\n",
    "    print(acc)\n",
    "    if acc > max(answers['Q2'], answers['Q4']):\n",
    "        print(f\"Found better c: c = {c}, acc = {acc}\")\n",
    "        if bestAcc is None: \n",
    "            bestAcc = acc\n",
    "        elif bestAcc < acc:\n",
    "            bestAcc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = bestAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': [(34211, 'the'),\n",
       "  (19392, 'and'),\n",
       "  (18791, 'a'),\n",
       "  (18077, 'to'),\n",
       "  (15043, 'game'),\n",
       "  (14095, 'of'),\n",
       "  (13000, 'is'),\n",
       "  (12735, 'you'),\n",
       "  (12204, 'i'),\n",
       "  (11824, 'it')],\n",
       " 'Q2': 0.6374,\n",
       " 'Q3': [(1.453457336521869, 1.453457336521869),\n",
       "  (0.22951619056889208, 0.45903238113778416),\n",
       "  (2.2441251443275085, 4.488250288655017),\n",
       "  (0.3047810810948491, 2.4382486487587927),\n",
       "  (0.376647318462008, 1.129941955386024)],\n",
       " 'Q4': 0.6217,\n",
       " 'Q5': (0.48266773388727985, 'r65720011'),\n",
       " 'Q6': 0.6455}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "f = gzip.open(\"data/young_adult_20000.json.gz\")\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    # print(d['date_added'])\n",
    "    # print(type(d['date_added']))\n",
    "    d['datetime'] = dateutil.parser.parse(d['date_added'])\n",
    "    # print(d['datetime'])\n",
    "    # print(type(d['datetime']))\n",
    "    dataset.append(d)\n",
    "    if len(dataset) >= 20000:\n",
    "        break\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'dc3763cdb9b2cae805882878eebb6a32',\n",
       " 'book_id': '18471619',\n",
       " 'review_id': '66b2ba840f9bd36d6d27f46136fe4772',\n",
       " 'rating': 3,\n",
       " 'review_text': 'Sherlock Holmes and the Vampires of London \\n Release Date: April 2014 \\n Publisher: Darkhorse Comics \\n Story by: Sylvain Cordurie \\n Art by: Laci \\n Colors by: Axel Gonzabo \\n Cover by: Jean Sebastien Rossbach \\n ISDN: 9781616552664 \\n MSRP: $17.99 Hardcover \\n \"Sherlock Holmes died fighting Professor Moriarty in the Reichenbach Falls. \\n At least, that\\'s what the press claims. \\n However, Holmes is alive and well and taking advantage of his presumed death to travel the globe. \\n Unfortunately, Holmes\\'s plans are thwarted when a plague of vampirism haunts Britain. \\n This book collects Sherlock Holmes and the Vampires of London Volumes 1 and 2, originally created by French publisher Soleil.\" - Darkhorse Comics \\n When I received this copy of \"Sherlock Holmes and the Vampires of London\" I was Ecstatic! The cover art was awesome and it was about two of my favorite things, Sherlock Holmes and Vampires. I couldn\\'t wait to dive into this! \\n Unfortunately, that is where my excitement ended. The story takes place a month after Sherlock Holmes supposed death in his battle with Professor Moriarty. Sherlock\\'s plan to stay hidden and out of site are ruined when on a trip with his brother Mycroft, they stumble on the presence of vampires. That is about as much of Sherlock\\'s character that comes through the book. I can\\'t even tell you the story really because nothing and I mean nothing stuck with me after reading it. I never, ever got the sense of Sherlock Holmes anywhere in this graphic novel, nor any real sense of mystery or crime. It was just Sherlock somehow battling vampires that should have had absolutely no trouble snuffing him out in a fight, but somehow always surviving and holding his own against supernatural, super powerful, blazingly fast creatures. \\n The cover art is awesome and it truly made me excited to read this but everything else feel completely flat for me. I tried telling myself that \"it\\'s a graphic novel, it would be hard to translate mystery, details, emotion\" but then I remembered reading DC Comic\\'s \"Identity Crisis\" and realized that was a load of crap. I know it\\'s unfair to compare the two as \"Identity Crisis\" had popular mystery author Brad Meltzer writing it right? Yeah....no. The standard was set that day and there is more than enough talent out there to create a great story in a graphic novel. \\n That being said, it wasn\\'t a horrible story, it just didn\\'t grip me for feel anything like Sherlock Holmes to me. It was easy enough to follow but I felt no sense of tension, stakes or compassion for any of the characters. \\n As far as the vampires go, it\\'s hard to know what to expect anymore as there are so many different versions these days. This was the more classic version which I personally prefer, but again I didn\\'t find anything that portrayed their dominance, calm confidence or sexuality. There was definitely a presence of their physical prowess but somehow that was lost on me as easily as Sherlock was able to defend himself. I know it, wouldn\\'t do to kill of the main character, but this would have a been a great opportunity to build around the experience and beguiling nature of a vampire that had lived so many years of experience. Another chance to showcase Sherlock\\'s intellect in a battle of wits over strength in something more suitable for this sort of story as apposed to trying to make it feel like an action movie. \\n Maybe I expected to much and hoped to have at least a gripping premise or some sort of interesting plot or mystery but I didn\\'t find it here. This may be a must have for serious Sherlock Holmes fans that have to collect everything about him, but if you are looking for a great story inside a graphic novel, I would have to say pass on this one. \\n That artwork is good, cover is great, story is lacking so I am giving it 2.5 out of 5 stars.',\n",
       " 'date_added': 'Thu Dec 05 10:44:25 -0800 2013',\n",
       " 'date_updated': 'Thu Dec 05 10:45:15 -0800 2013',\n",
       " 'read_at': 'Tue Nov 05 00:00:00 -0800 2013',\n",
       " 'started_at': '',\n",
       " 'n_votes': 0,\n",
       " 'n_comments': 0,\n",
       " 'datetime': datetime.datetime(2013, 12, 5, 10, 44, 25, tzinfo=tzoffset(None, -28800))}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "for r in dataset:\n",
    "    uid, bid = r['user_id'], r['book_id']\n",
    "    reviewsPerUser[uid].append(bid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewLists = []\n",
    "for u in reviewsPerUser:\n",
    "    rl = list(reviewsPerUser[u])\n",
    "    rl.sort()\n",
    "    reviewLists.append(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Word2Vec(reviewLists,\n",
    "                  min_count=1, # Words/items with fewer instances are discarded\n",
    "                  vector_size=5, # Model dimensionality\n",
    "                  window=3, # Window size\n",
    "                  sg=1) # Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstRev = dataset[0]['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18471619'"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstRev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model5.wv.similar_by_word(firstRev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList([x[1] for x in answers['Q7']], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw4.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
